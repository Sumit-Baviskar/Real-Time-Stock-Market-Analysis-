# -*- coding: utf-8 -*-
"""kafka_consumer_to_s3.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u3Mvn6-ZJ1E1J5v7lfB-xxbUQIbJLDfF
"""

from kafka import KafkaConsumer
import boto3
import json
from datetime import datetime

# ðŸ”Œ CONNECT TO KAFKA
consumer = KafkaConsumer(
    'stock-data-stream',
    bootstrap_servers='your-ec2-ip:9092',
    auto_offset_reset='latest',
    enable_auto_commit=True,
    value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

# ðŸª£ S3 CONFIG
s3 = boto3.client('s3', region_name='ap-south-1')  # Use your AWS region
bucket_name = 'your-s3-bucket-name'
prefix = 'kafka-data/'  # Folder inside bucket

print("ðŸš€ STARTED CONSUMING AND WRITING TO S3...\n")

for message in consumer:
    stock_data = message.value
    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S-%f')
    file_name = f"{prefix}{stock_data['symbol']}_{timestamp}.json"
    json_data = json.dumps(stock_data)
    s3.put_object(Bucket=bucket_name, Key=file_name, Body=json_data)
    print(f"âœ… Uploaded: {file_name}")